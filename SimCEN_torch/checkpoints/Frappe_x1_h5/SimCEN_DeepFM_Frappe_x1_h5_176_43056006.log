2023-11-12 01:25:11,231 P685179 INFO Params: {
    "alpha": "0.01",
    "batch_size": "10000",
    "cl_temperature": "0.4",
    "data_format": "h5",
    "data_root": "../../../data/",
    "dataset_id": "Frappe_x1_h5",
    "debug_mode": "False",
    "early_stop_patience": "2",
    "ego_batch_norm": "True",
    "ego_dropout": "0.1",
    "ego_hidden_activations": "relu",
    "embedding_dim": "16",
    "embedding_regularizer": "0.05",
    "epochs": "100",
    "eval_steps": "None",
    "feature_cols": "[{'active': True, 'dtype': 'float', 'name': ['user', 'item', 'daytime', 'weekday', 'isweekend', 'homework', 'cost', 'weather', 'country', 'city'], 'type': 'categorical'}]",
    "feature_config": "None",
    "feature_specs": "None",
    "gpu": "0",
    "group_id": "None",
    "hidden_units": "[480, 480, 480]",
    "label_col": "{'dtype': 'float', 'name': 'label'}",
    "learning_rate": "0.001",
    "loss": "binary_crossentropy",
    "metrics": "['logloss', 'AUC']",
    "min_categr_count": "2",
    "model": "SimCEN_DeepFM",
    "model_id": "SimCEN_DeepFM_Frappe_x1_h5_176_43056006",
    "model_root": "./checkpoints/",
    "monitor": "{'AUC': 1, 'logloss': -1}",
    "monitor_mode": "max",
    "net_regularizer": "0",
    "num_workers": "4",
    "optimizer": "adam",
    "pickle_feature_encoder": "True",
    "save_best_only": "True",
    "seed": "2023",
    "shuffle": "True",
    "task": "binary_classification",
    "test_data": "../../../data/Frappe_x1_h5/test.h5",
    "through_dropout": "0.3",
    "train_data": "../../../data/Frappe_x1_h5/train.h5",
    "use_features": "None",
    "v1_batch_norm": "True",
    "v1_dropout": "0.3",
    "v1_hidden_activations": "mish",
    "v2_batch_norm": "True",
    "v2_dropout": "0.1",
    "v2_hidden_activations": "gelu",
    "valid_data": "../../../data/Frappe_x1_h5/valid.h5",
    "verbose": "1"
}
2023-11-12 01:25:11,231 P685179 INFO Load feature_map from json: ../../../data/Frappe_x1_h5/feature_map.json
2023-11-12 01:25:11,231 P685179 INFO Set column index...
2023-11-12 01:25:11,231 P685179 INFO Feature specs: {
    "city": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 232, 'vocab_size': 233}",
    "cost": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 3, 'vocab_size': 4}",
    "country": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 81, 'vocab_size': 82}",
    "daytime": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 8, 'vocab_size': 9}",
    "homework": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 4, 'vocab_size': 5}",
    "isweekend": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 3, 'vocab_size': 4}",
    "item": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 4083, 'vocab_size': 4084}",
    "user": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 941, 'vocab_size': 942}",
    "weather": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 10, 'vocab_size': 11}",
    "weekday": "{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 8, 'vocab_size': 9}"
}
2023-11-12 01:25:20,286 P685179 INFO Total number of parameters: 884089.
2023-11-12 01:25:20,286 P685179 INFO Loading data...
2023-11-12 01:25:20,286 P685179 INFO Loading data from h5: ../../../data/Frappe_x1_h5/train.h5
2023-11-12 01:25:20,302 P685179 INFO Train samples: total/202027, blocks/1
2023-11-12 01:25:20,303 P685179 INFO Loading data from h5: ../../../data/Frappe_x1_h5/valid.h5
2023-11-12 01:25:20,306 P685179 INFO Validation samples: total/57722, blocks/1
2023-11-12 01:25:20,306 P685179 INFO Loading train and validation data done.
2023-11-12 01:25:20,306 P685179 INFO Start training: 21 batches/epoch
2023-11-12 01:25:20,306 P685179 INFO ************ Epoch=1 start ************
2023-11-12 01:25:22,891 P685179 INFO Train loss: 0.533485
2023-11-12 01:25:22,891 P685179 INFO Evaluation @epoch 1 - batch 21: 
2023-11-12 01:25:24,431 P685179 INFO ===
2023-11-12 01:25:24,431 P685179 INFO [Metrics] AUC: 0.926375 - logloss: 0.619284
2023-11-12 01:25:24,431 P685179 INFO Save best model: monitor(max)=0.307091
2023-11-12 01:25:24,593 P685179 INFO ************ Epoch=1 end ************
2023-11-12 01:25:27,669 P685179 INFO Train loss: 0.396908
2023-11-12 01:25:27,670 P685179 INFO Evaluation @epoch 2 - batch 21: 
2023-11-12 01:25:29,212 P685179 INFO ===
2023-11-12 01:25:29,212 P685179 INFO [Metrics] AUC: 0.933649 - logloss: 0.582510
2023-11-12 01:25:29,212 P685179 INFO Save best model: monitor(max)=0.351139
2023-11-12 01:25:29,539 P685179 INFO ************ Epoch=2 end ************
2023-11-12 01:25:32,762 P685179 INFO Train loss: 0.329236
2023-11-12 01:25:32,763 P685179 INFO Evaluation @epoch 3 - batch 21: 
2023-11-12 01:25:34,305 P685179 INFO ===
2023-11-12 01:25:34,305 P685179 INFO [Metrics] AUC: 0.928999 - logloss: 0.565852
2023-11-12 01:25:34,305 P685179 INFO Save best model: monitor(max)=0.363148
2023-11-12 01:25:34,477 P685179 INFO ************ Epoch=3 end ************
2023-11-12 01:25:37,283 P685179 INFO Train loss: 0.279273
2023-11-12 01:25:37,283 P685179 INFO Evaluation @epoch 4 - batch 21: 
2023-11-12 01:25:39,161 P685179 INFO ===
2023-11-12 01:25:39,161 P685179 INFO [Metrics] AUC: 0.965309 - logloss: 0.360082
2023-11-12 01:25:39,161 P685179 INFO Save best model: monitor(max)=0.605227
2023-11-12 01:25:39,478 P685179 INFO ************ Epoch=4 end ************
2023-11-12 01:25:42,552 P685179 INFO Train loss: 0.251735
2023-11-12 01:25:42,553 P685179 INFO Evaluation @epoch 5 - batch 21: 
2023-11-12 01:25:44,306 P685179 INFO ===
2023-11-12 01:25:44,306 P685179 INFO [Metrics] AUC: 0.978396 - logloss: 0.173729
2023-11-12 01:25:44,307 P685179 INFO Save best model: monitor(max)=0.804666
2023-11-12 01:25:44,527 P685179 INFO ************ Epoch=5 end ************
2023-11-12 01:25:47,708 P685179 INFO Train loss: 0.235401
2023-11-12 01:25:47,708 P685179 INFO Evaluation @epoch 6 - batch 21: 
2023-11-12 01:25:49,236 P685179 INFO ===
2023-11-12 01:25:49,236 P685179 INFO [Metrics] AUC: 0.980289 - logloss: 0.173527
2023-11-12 01:25:49,236 P685179 INFO Save best model: monitor(max)=0.806762
2023-11-12 01:25:49,407 P685179 INFO ************ Epoch=6 end ************
2023-11-12 01:25:51,974 P685179 INFO Train loss: 0.225385
2023-11-12 01:25:51,975 P685179 INFO Evaluation @epoch 7 - batch 21: 
2023-11-12 01:25:53,505 P685179 INFO ===
2023-11-12 01:25:53,505 P685179 INFO [Metrics] AUC: 0.981952 - logloss: 0.187432
2023-11-12 01:25:53,505 P685179 INFO Monitor(max)=0.794520 STOP!
2023-11-12 01:25:53,505 P685179 INFO Reduce learning rate on plateau: 0.000100
2023-11-12 01:25:53,662 P685179 INFO ************ Epoch=7 end ************
2023-11-12 01:25:56,185 P685179 INFO Train loss: 0.195137
2023-11-12 01:25:56,185 P685179 INFO Evaluation @epoch 8 - batch 21: 
2023-11-12 01:25:57,772 P685179 INFO ===
2023-11-12 01:25:57,772 P685179 INFO [Metrics] AUC: 0.983655 - logloss: 0.154414
2023-11-12 01:25:57,772 P685179 INFO Save best model: monitor(max)=0.829241
2023-11-12 01:25:57,944 P685179 INFO ************ Epoch=8 end ************
2023-11-12 01:26:00,405 P685179 INFO Train loss: 0.179563
2023-11-12 01:26:00,406 P685179 INFO Evaluation @epoch 9 - batch 21: 
2023-11-12 01:26:01,856 P685179 INFO ===
2023-11-12 01:26:01,856 P685179 INFO [Metrics] AUC: 0.984159 - logloss: 0.151391
2023-11-12 01:26:01,857 P685179 INFO Save best model: monitor(max)=0.832768
2023-11-12 01:26:02,041 P685179 INFO ************ Epoch=9 end ************
2023-11-12 01:26:04,520 P685179 INFO Train loss: 0.168947
2023-11-12 01:26:04,520 P685179 INFO Evaluation @epoch 10 - batch 21: 
2023-11-12 01:26:05,941 P685179 INFO ===
2023-11-12 01:26:05,942 P685179 INFO [Metrics] AUC: 0.984604 - logloss: 0.151024
2023-11-12 01:26:05,942 P685179 INFO Save best model: monitor(max)=0.833580
2023-11-12 01:26:06,089 P685179 INFO ************ Epoch=10 end ************
2023-11-12 01:26:09,573 P685179 INFO Train loss: 0.162038
2023-11-12 01:26:09,573 P685179 INFO Evaluation @epoch 11 - batch 21: 
2023-11-12 01:26:11,097 P685179 INFO ===
2023-11-12 01:26:11,097 P685179 INFO [Metrics] AUC: 0.984583 - logloss: 0.153358
2023-11-12 01:26:11,097 P685179 INFO Monitor(max)=0.831225 STOP!
2023-11-12 01:26:11,097 P685179 INFO Reduce learning rate on plateau: 0.000010
2023-11-12 01:26:11,260 P685179 INFO ************ Epoch=11 end ************
2023-11-12 01:26:13,848 P685179 INFO Train loss: 0.157153
2023-11-12 01:26:13,848 P685179 INFO Evaluation @epoch 12 - batch 21: 
2023-11-12 01:26:15,316 P685179 INFO ===
2023-11-12 01:26:15,316 P685179 INFO [Metrics] AUC: 0.984537 - logloss: 0.157061
2023-11-12 01:26:15,317 P685179 INFO Monitor(max)=0.827476 STOP!
2023-11-12 01:26:15,317 P685179 INFO Reduce learning rate on plateau: 0.000001
2023-11-12 01:26:15,317 P685179 INFO ********* Epoch==12 early stop *********
2023-11-12 01:26:15,457 P685179 INFO Training finished.
2023-11-12 01:26:15,457 P685179 INFO Load best model: /root/autodl-tmp/model_zoo/SimCEN/SimCEN_torch/checkpoints/Frappe_x1_h5/SimCEN_DeepFM_Frappe_x1_h5_176_43056006.model
2023-11-12 01:26:15,534 P685179 INFO ****** Validation evaluation ******
2023-11-12 01:26:17,514 P685179 INFO ===
2023-11-12 01:26:17,514 P685179 INFO [Metrics] logloss: 0.151024 - AUC: 0.984604
2023-11-12 01:26:17,563 P685179 INFO ******** Test evaluation ********
2023-11-12 01:26:17,564 P685179 INFO Loading data...
2023-11-12 01:26:17,564 P685179 INFO Loading data from h5: ../../../data/Frappe_x1_h5/test.h5
2023-11-12 01:26:17,566 P685179 INFO Test samples: total/28860, blocks/1
2023-11-12 01:26:17,567 P685179 INFO Loading test data done.
2023-11-12 01:26:19,283 P685179 INFO ===
2023-11-12 01:26:19,283 P685179 INFO [Metrics] logloss: 0.152923 - AUC: 0.984349
